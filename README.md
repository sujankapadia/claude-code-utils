# Claude Code Analytics

A comprehensive analytics platform for [Claude Code](https://claude.com/claude-code) that automatically captures, archives, and analyzes your AI development conversations. Features an interactive dashboard, powerful search, and AI-powered insights across all your sessions.

## Overview

Claude Code Analytics transforms your AI development workflow into actionable insights. It automatically captures every conversation, stores them in a searchable database, and provides an interactive dashboard to explore your development patterns, tool usage, and decision-making process.

**How it works:**
1. **Capture** - SessionEnd hooks automatically export conversations when you exit Claude Code
2. **Store** - Conversations are imported into a SQLite database with full-text search
3. **Analyze** - Interactive Streamlit dashboard provides search, analytics, and AI-powered insights

## Key Features

### ğŸ“Š Interactive Dashboard

The Streamlit-based dashboard is your primary interface for exploring conversations:

- **Session Browser** - View, filter, and navigate all your Claude Code sessions with pagination support
- **Conversation Viewer** - Terminal-style interface that faithfully recreates your sessions:
  - Inline tool calls and results
  - Role-based filtering (user/assistant)
  - Content search within sessions
  - Token usage display
  - Deep linking to specific messages from search results
- **Analytics Dashboard** - Visual insights into your development patterns:
  - Messages and token usage over time
  - Tool usage distribution and error rates
  - Project activity metrics
  - Daily activity trends
- **Full-Text Search** - FTS5-powered search across all messages, tool inputs, and tool results:
  - Scope filtering (messages, tool inputs/results)
  - Project and date range filters
  - Highlighted search results with context
  - Direct navigation to matching messages
  - MCP tool usage analysis
- **AI-Powered Analysis** - Run sophisticated analysis on any session:
  - Technical decisions extraction
  - Error pattern analysis
  - AI agent usage patterns
  - Custom analysis with your own prompts
  - 300+ model selection via OpenRouter or Gemini

### ğŸ” Search & Discovery

- **Full-text search** - Lightning-fast FTS5 search across millions of tokens
- **Deep linking** - Search results link directly to specific messages in conversations
- **Advanced filtering** - Filter by project, date range, role, tool name
- **MCP tool tracking** - Dedicated analytics for MCP server usage
- **Message-level precision** - Every tool use is linked to its exact message

### ğŸ’¾ Automatic Archiving

- **Hook-based capture** - Conversations automatically export on session end
- **Dual-format storage** - Raw JSONL for programmatic access, formatted text for reading
- **Project organization** - Conversations organized by the project directory they occurred in
- **Incremental imports** - Database updates efficiently with only new content
- **Session resumption** - Correctly handles resumed sessions and updates

### ğŸ¤– AI-Powered Analysis

- **300+ models** - Access entire OpenRouter catalog or use Google Gemini directly
- **Curated selection** - Quick-select from 13 newest premium models (2025):
  - **Budget**: Qwen3, Llama 4 Scout, Mistral Small ($0.06-$0.10/1M tokens)
  - **Balanced**: DeepSeek V3.2, Gemini 3 Flash, Claude Haiku 4.5 ($0.26-$1.75/1M tokens)
  - **Premium**: Gemini 3 Pro, Claude Sonnet 4.5, Grok 4, Claude Opus 4.5 ($2-$5/1M tokens)
- **Pre-built analysis types**:
  - Technical Decisions - Extract decisions, alternatives, and reasoning
  - Error Patterns - Identify recurring issues, root causes, resolutions
  - AI Agent Usage - Understand how you use AI for prototyping and discovery
  - Custom - Write your own analysis prompts
- **Templated prompts** - Jinja2-based templates for easy customization
- **Export results** - Save analysis as markdown files

### ğŸ“ˆ Comprehensive Analytics

- **Token tracking** - Input, output, and cache metrics (creation, read, 5m, 1h)
- **Tool usage stats** - Track which tools you use most, error rates, session distribution
- **Daily trends** - Message volume, token usage, and activity over time
- **Project insights** - Compare activity levels across different projects

## Quick Start

### 1. Install

```bash
git clone https://github.com/yourusername/claude-code-utils.git
cd claude-code-utils
./install.sh
```

The installer sets up hooks, creates directories, and configures Claude Code to automatically export conversations.

### 2. Create Database

```bash
# Create database schema
python3 scripts/create_database.py

# Import existing conversations
python3 scripts/import_conversations.py

# Create search index
python3 scripts/create_fts_index.py
```

### 3. Launch Dashboard

```bash
./run_dashboard.sh
```

The dashboard opens at `http://localhost:8501`. Start exploring your conversations!

### 4. (Optional) Configure AI Analysis

To use AI-powered analysis features:

```bash
# Option 1: OpenRouter (300+ models)
export OPENROUTER_API_KEY="sk-or-your-key-here"

# Option 2: Google Gemini (direct)
export GOOGLE_API_KEY="your-api-key-here"
```

Get API keys from [OpenRouter](https://openrouter.ai/keys) or [Google AI Studio](https://aistudio.google.com/app/apikey).

## Using the Dashboard

### Browse Sessions

The **Browse Sessions** page shows all your conversations:
- Filter by project, date range, or minimum message count
- Sort by date or activity level
- Pagination for large conversation histories
- Click any session to view full conversation

### Search Conversations

The **Search** page provides powerful full-text search:
- Search across messages, tool inputs, or tool results
- Filter by project, date range, or specific tools
- View MCP tool usage statistics
- Click search results to jump directly to matching messages in context

### View Analytics

The **Analytics Dashboard** provides visual insights:
- Tool usage distribution (top 10 tools by usage)
- Daily activity trends (messages, tokens, sessions)
- Token usage over time (input vs output)
- Project statistics (sorted by message volume)

### Run AI Analysis

The **AI Analysis** page lets you analyze sessions with LLMs:
1. Select a session from the dropdown
2. Choose analysis type or write custom prompt
3. Select model (browse 300+ options or pick from curated list)
4. Adjust temperature (default: 0.1 for deterministic analysis)
5. Run analysis and optionally export to markdown

## Advanced Usage

### CLI Tools

#### Search Conversations

```bash
python3 scripts/search_fts.py "error handling"
```

#### Run Analysis from CLI

```bash
# Analyze technical decisions
python3 scripts/analyze_session.py <session-id> --type=decisions

# Specify model and save output
python3 scripts/analyze_session.py <session-id> \
  --type=errors \
  --model=anthropic/claude-sonnet-4.5 \
  --output=analysis.md

# Custom analysis
python3 scripts/analyze_session.py <session-id> \
  --type=custom \
  --prompt="Summarize key technical insights"
```

**Popular models:**
- `deepseek/deepseek-v3.2` - Best balance (default, $0.26/1M)
- `anthropic/claude-sonnet-4.5` - Highest quality ($3.00/1M)
- `openai/gpt-5.2-chat` - Latest GPT ($1.75/1M)
- `google/gemini-3-flash-preview` - 1M context window ($0.50/1M)

### Incremental Database Updates

Run the import script anytime to update the database with new conversations:

```bash
python3 scripts/import_conversations.py
```

The script automatically:
- Detects existing sessions
- Imports only new messages
- Updates session metadata (end times, message counts)
- Preserves all existing data with zero duplicates
- Works efficiently on active or completed sessions

### Manual Export

Convert JSONL transcripts to readable text format:

```bash
~/.claude/scripts/pretty-print-transcript.py /path/to/transcript.jsonl output.txt

# Or via stdin/stdout
cat transcript.jsonl | ~/.claude/scripts/pretty-print-transcript.py > output.txt
```

### Custom Analysis Prompts

Create custom analysis templates in `prompts/`:

1. Create a new `.md` file with your Jinja2 template
2. Add metadata to `prompts/metadata.yaml`
3. Use from dashboard or CLI with `--type=your_template_name`

See `prompts/README.md` for detailed instructions.

## How It Works

### Architecture

```
Claude Code Session
       â†“
SessionEnd Hook (export-conversation.sh)
       â†“
~/claude-conversations/
  â”œâ”€â”€ project-name/
  â”‚   â”œâ”€â”€ session-YYYYMMDD-HHMMSS.jsonl  (raw data)
  â”‚   â””â”€â”€ session-YYYYMMDD-HHMMSS.txt    (readable format)
       â†“
Import Script (import_conversations.py)
       â†“
SQLite Database (conversations.db)
  â”œâ”€â”€ projects
  â”œâ”€â”€ sessions
  â”œâ”€â”€ messages
  â”œâ”€â”€ tool_uses
  â””â”€â”€ fts_messages (full-text search index)
       â†“
Streamlit Dashboard
  â”œâ”€â”€ Browse & filter sessions
  â”œâ”€â”€ Search conversations
  â”œâ”€â”€ View analytics
  â””â”€â”€ Run AI analysis
```

### Hook System

The `export-conversation.sh` hook runs automatically when you exit Claude Code:

1. Receives current working directory and transcript path
2. Finds the most recent transcript (handles session resumption)
3. Creates project-specific directory structure
4. Copies JSONL file with timestamp
5. Generates human-readable text version
6. Logs to `~/.claude/export-debug.log`

### Database Schema

The SQLite database uses a normalized schema:

- **projects** - Unique project directories
- **sessions** - Conversation sessions with metadata
- **messages** - Individual messages with token tracking
- **tool_uses** - Tool calls linked to messages via `message_index`
- **fts_messages** - FTS5 full-text search index
- **Views** - Pre-aggregated statistics for performance

See `docs/database.md` for complete schema documentation.

### File Organization

Exported conversations are organized by project:

```
~/claude-conversations/
â”œâ”€â”€ project-name-1/
â”‚   â”œâ”€â”€ session-20250113-143022.jsonl
â”‚   â”œâ”€â”€ session-20250113-143022.txt
â”‚   â”œâ”€â”€ session-20250113-151430.jsonl
â”‚   â””â”€â”€ session-20250113-151430.txt
â”œâ”€â”€ project-name-2/
â”‚   â””â”€â”€ session-20250114-091500.jsonl
â””â”€â”€ conversations.db
```

### Readable Text Format

The generated `.txt` files provide a clean, readable format:

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USER (2025-01-13 14:30:22)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Can you help me fix the bug in the authentication module?

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CLAUDE (2025-01-13 14:30:24)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
I'll help you fix the authentication bug. Let me first examine the
authentication module to understand the issue.

[Tool: Read]
$ Read file_path=/path/to/auth.js

[Tool Result]
1  function authenticate(user, password) {
2    if (user && password) {
3      return true;
4    }
5  }
```

## Installation Details

### Automated Installation (Recommended)

The `install.sh` script handles everything:

```bash
./install.sh
```

It will:
- Create `~/.claude/scripts/` and `~/claude-conversations/` directories
- Copy hook and formatting scripts
- Set executable permissions
- Update `~/.claude/settings.json` with SessionEnd hook (backs up existing settings)

**Requirements:** The script uses `jq` for JSON manipulation. Install with:
- macOS: `brew install jq`
- Linux: `apt-get install jq`

If `jq` is not available, the script provides manual configuration instructions.

### Manual Installation

If you prefer manual setup:

#### 1. Create directories

```bash
mkdir -p ~/.claude/scripts
mkdir -p ~/claude-conversations
```

#### 2. Copy scripts

```bash
cp hooks/export-conversation.sh ~/.claude/scripts/
cp scripts/pretty-print-transcript.py ~/.claude/scripts/
chmod +x ~/.claude/scripts/export-conversation.sh
chmod +x ~/.claude/scripts/pretty-print-transcript.py
```

#### 3. Configure hook

Add to `~/.claude/settings.json`:

```json
{
  "hooks": {
    "SessionEnd": [
      {
        "matcher": "",
        "hooks": [
          {
            "type": "command",
            "command": "bash ~/.claude/scripts/export-conversation.sh"
          }
        ]
      }
    ]
  }
}
```

If you have existing hooks, merge the `SessionEnd` entry into your existing `hooks` object.

#### 4. Install Python dependencies

```bash
pip install streamlit pandas altair google-generativeai openai jinja2 pyyaml python-dotenv
```

### Troubleshooting

#### Conversations not exporting

Check the debug log:
```bash
cat ~/.claude/export-debug.log
```

Common issues:
- Hook not configured in `~/.claude/settings.json`
- Scripts not executable (`chmod +x`)
- Incorrect paths in settings

#### Permission errors

Ensure directories are writable:
```bash
chmod 755 ~/claude-conversations
chmod 755 ~/.claude/scripts
```

#### Import errors

If database import fails:
- Verify JSONL files exist in `~/claude-conversations/`
- Check file permissions
- Ensure Python 3.7+ is installed
- Run with verbose output: `python3 scripts/import_conversations.py -v`

#### Dashboard not launching

- Install dependencies: `pip install streamlit pandas altair`
- Check port 8501 is available
- Try alternate port: `streamlit run streamlit_app/app.py --server.port=8502`

## Project Structure

```
claude-code-utils/
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ export-conversation.sh       # SessionEnd hook for auto-export
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ pretty-print-transcript.py   # Convert JSONL to readable text
â”‚   â”œâ”€â”€ create_database.py           # Create SQLite database schema
â”‚   â”œâ”€â”€ import_conversations.py      # Import conversations to database
â”‚   â”œâ”€â”€ create_fts_index.py          # Create full-text search index
â”‚   â”œâ”€â”€ search_fts.py                # CLI search tool
â”‚   â””â”€â”€ analyze_session.py           # CLI analysis tool
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py                       # Dashboard entry point
â”‚   â”œâ”€â”€ models/                      # Pydantic data models
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ services/                    # Business logic layer
â”‚   â”‚   â””â”€â”€ database_service.py
â”‚   â””â”€â”€ pages/                       # Dashboard pages
â”‚       â”œâ”€â”€ browser.py               # Session browser
â”‚       â”œâ”€â”€ conversation.py          # Conversation viewer
â”‚       â”œâ”€â”€ search.py                # Full-text search
â”‚       â”œâ”€â”€ analytics.py             # Analytics dashboard
â”‚       â””â”€â”€ ai_analysis.py           # AI-powered analysis
â”œâ”€â”€ prompts/                         # Analysis prompt templates
â”‚   â”œâ”€â”€ metadata.yaml                # Analysis type definitions
â”‚   â”œâ”€â”€ decisions.md                 # Technical decisions prompt
â”‚   â”œâ”€â”€ errors.md                    # Error patterns prompt
â”‚   â””â”€â”€ agent_usage.md               # AI agent usage analysis
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ database.md                  # Database schema details
â”‚   â”œâ”€â”€ search-feature.md            # Search implementation
â”‚   â””â”€â”€ deep-linking-implementation.md
â”œâ”€â”€ install.sh                       # Automated installer
â”œâ”€â”€ run_dashboard.sh                 # Dashboard launcher
â””â”€â”€ README.md                        # This file
```

## Documentation

- **[Database Schema](docs/database.md)** - Complete schema documentation
- **[Search Feature](docs/search-feature.md)** - Full-text search implementation
- **[Deep Linking](docs/deep-linking-implementation.md)** - Technical details on search-to-conversation navigation
- **[Custom Prompts](prompts/README.md)** - How to create custom analysis prompts

## Future Roadmap

- **Vector embeddings** - Semantic search across conversations
- **PII detection** - Identify potential sensitive data
- **Cost tracking** - Monitor LLM API costs per analysis
- **Model comparison** - A/B test analysis quality across models
- **Export formats** - HTML, PDF conversation exports
- **Real-time analysis** - Analyze conversations as they happen
- **Cloud sync** - Optional backup to cloud storage

## Contributing

Contributions are welcome! Feel free to:
- Report bugs or request features via GitHub Issues
- Submit pull requests
- Share your custom analysis prompts
- Suggest new analytics visualizations

## License

MIT License - Use and modify freely.

## Resources

- [Claude Code Documentation](https://docs.claude.com/en/docs/claude-code)
- [Claude Code Hooks Guide](https://docs.claude.com/en/docs/claude-code/hooks)
- [OpenRouter API](https://openrouter.ai/)
- [Google Gemini API](https://ai.google.dev/)
